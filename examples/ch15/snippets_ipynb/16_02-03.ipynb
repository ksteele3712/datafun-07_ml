{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16.2 Case Study: Classification with k-Nearest Neighbors and the Digits Dataset, Part 1\n",
    "\n",
    "**This file contains Sections 16.2 and 16.3 and all of their subsections and Self Check exercises**\n",
    "\n",
    "### Classification Problems\n",
    "### Our Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Self Check Exercises check mark image](files/art/check.png)\n",
    "## 16.2 Self Check\n",
    "\n",
    "**1. _(Fill-In)_** `________` classification divides samples into two distinct classes, and `________`-classification divides samples into many distinct classes.\n",
    "\n",
    "**Answer:** binary, multi. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.2.1 k-Nearest Neighbors Algorithm\n",
    "### Hyperparameters and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Self Check Exercises check mark image](files/art/check.png)\n",
    "## 16.2.1 Self Check\n",
    "**1. _(True/False)_** In machine learning, a model implements a machine-learning algorithm. In scikit-learn, models are called estimators.\n",
    "\n",
    "**Answer:** True.\n",
    "\n",
    "**2. _(Fill-In)_** The process of choosing the best value of *k* for the k-nearest neighbors algorithm is called `________`\n",
    "\n",
    "**Answer:** hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.2.2 Loading the Dataset\n",
    "\n",
    "**We added `%matplotlib inline` to enable Matplotlib in this notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmatplotlib\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minline\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_digits\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\interactiveshell.py:2504\u001b[39m, in \u001b[36mInteractiveShell.run_line_magic\u001b[39m\u001b[34m(self, magic_name, line, _stack_depth)\u001b[39m\n\u001b[32m   2502\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mlocal_ns\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mself\u001b[39m.get_local_scope(stack_depth)\n\u001b[32m   2503\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m-> \u001b[39m\u001b[32m2504\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2506\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2507\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2508\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2509\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\magics\\pylab.py:103\u001b[39m, in \u001b[36mPylabMagics.matplotlib\u001b[39m\u001b[34m(self, line)\u001b[39m\n\u001b[32m     98\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m     99\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAvailable matplotlib backends: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    100\u001b[39m         % _list_matplotlib_backends_and_gui_loops()\n\u001b[32m    101\u001b[39m     )\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     gui, backend = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshell\u001b[49m\u001b[43m.\u001b[49m\u001b[43menable_matplotlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgui\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m     \u001b[38;5;28mself\u001b[39m._show_matplotlib_backend(args.gui, backend)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\interactiveshell.py:3787\u001b[39m, in \u001b[36mInteractiveShell.enable_matplotlib\u001b[39m\u001b[34m(self, gui)\u001b[39m\n\u001b[32m   3784\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib_inline\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend_inline\u001b[39;00m\n\u001b[32m   3786\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pylabtools \u001b[38;5;28;01mas\u001b[39;00m pt\n\u001b[32m-> \u001b[39m\u001b[32m3787\u001b[39m gui, backend = \u001b[43mpt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind_gui_and_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgui\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpylab_gui_select\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gui != \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3790\u001b[39m     \u001b[38;5;66;03m# If we have our first gui selection, store it\u001b[39;00m\n\u001b[32m   3791\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pylab_gui_select \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\pylabtools.py:338\u001b[39m, in \u001b[36mfind_gui_and_backend\u001b[39m\u001b[34m(gui, gui_select)\u001b[39m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfind_gui_and_backend\u001b[39m(gui=\u001b[38;5;28;01mNone\u001b[39;00m, gui_select=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    322\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Given a gui string return the gui and mpl backend.\u001b[39;00m\n\u001b[32m    323\u001b[39m \n\u001b[32m    324\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    335\u001b[39m \u001b[33;03m    'WXAgg','Qt4Agg','module://matplotlib_inline.backend_inline','agg').\u001b[39;00m\n\u001b[32m    336\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\n\u001b[32m    340\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _matplotlib_manages_backends():\n\u001b[32m    341\u001b[39m         backend_registry = matplotlib.backends.registry.backend_registry\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Sample and Target Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.target[::100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Sample Digit Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.images[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Data for Use with Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.data[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Self Check Exercises check mark image](files/art/check.png)\n",
    "## 16.2.2 Self Check\n",
    "\n",
    "**1. _(Fill-In)_** A `Bunch` object’s  `________` and `________` attributes are NumPy arrays containing the dataset’s samples and labels, respectively.\n",
    "\n",
    "**Answer:**  `data`, `target`.\n",
    "\n",
    "**2. _(True/False)_** A scikit-learn `Bunch` object contains only a dataset’s data.\n",
    "\n",
    "**Answer:** False. A scikit-learn `Bunch` object contains a dataset’s data and information about the dataset (called metadata), available through the `DESCR` attribute.\n",
    "\n",
    "**3. _(IPython Session)_** For sample number `22` in the Digits dataset, display the 8-by-8 image data and numeric value of the digit the image represents.\n",
    "\n",
    "**Answer:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.images[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.target[22]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.2.3 Visualizing the Data\n",
    "### Creating the Diagram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m figure, axes = \u001b[43mplt\u001b[49m.subplots(nrows=\u001b[32m4\u001b[39m, ncols=\u001b[32m6\u001b[39m, figsize=(\u001b[32m6\u001b[39m, \u001b[32m4\u001b[39m))\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m### Displaying Each Image and Removing the Axes Labels \u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(axes.ravel(), digits.images, digits.target):\n",
      "\u001b[31mNameError\u001b[39m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "figure, axes = plt.subplots(nrows=4, ncols=6, figsize=(6, 4))\n",
    "\n",
    "### Displaying Each Image and Removing the Axes Labels \n",
    "\n",
    "for item in zip(axes.ravel(), digits.images, digits.target):\n",
    "    axes, image, target = item\n",
    "    axes.imshow(image, cmap=plt.cm.gray_r)\n",
    "    axes.set_xticks([])  # remove x-axis tick marks\n",
    "    axes.set_yticks([])  # remove y-axis tick marks\n",
    "    axes.set_title(target)\n",
    "plt.tight_layout()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This placeholder cell was added because we had to combine \n",
    "# the sections snippets 12-13 for the visualization to work in Jupyter\n",
    "# and want the subsequent snippet numbers to match the book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Self Check Exercises check mark image](files/art/check.png)\n",
    "## 16.2.3 Self Check\n",
    "**1. _(Fill-In)_** The process of familiarizing yourself with your data is called `________`.\n",
    "\n",
    "**Answer:**  data exploration.\n",
    "\n",
    "**2. _(IPython Session)_** Display the image for sample number `22` of the Digits dataset. \n",
    "\n",
    "**Answer:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m axes = \u001b[43mplt\u001b[49m.subplot()\n\u001b[32m      3\u001b[39m image = plt.imshow(digits.images[\u001b[32m22\u001b[39m], cmap=plt.cm.gray_r)\n\u001b[32m      5\u001b[39m xticks = axes.set_xticks([])\n",
      "\u001b[31mNameError\u001b[39m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "axes = plt.subplot()\n",
    "\n",
    "image = plt.imshow(digits.images[22], cmap=plt.cm.gray_r)\n",
    "\n",
    "xticks = axes.set_xticks([])\n",
    "\n",
    "yticks = axes.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder due to merge of prior cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder due to merge of prior cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder due to merge of prior cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.2.4 Splitting the Data for Training and Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     digits.data, digits.target, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing Set Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Self Check Exercises check mark image](files/art/check.png)\n",
    "## 16.2.4 Self Check\n",
    "**1. _(True/False)_** You should typically use all of a dataset’s data to train a model.\n",
    "\n",
    "**Answer:** False. It’s important to set aside a portion of your data for testing, so you can evaluate a model’s performance using data that the model has not yet seen. \n",
    "\n",
    "**2. _(Discussion)_** For the Digits dataset, what numbers of samples would the following statement reserve for training and testing purposes? \n",
    "\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    digits.data, digits.target, test_size=0.40)\n",
    "```\n",
    "**Answer:** 1078 and 719."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.2.5 Creating the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.2.6 Training the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Self Check Exercises check mark image](files/art/check.png)\n",
    "## 16.2.6 Self Check\n",
    "**1. _(Fill-In)_** The `KNeighborsClassifier` is said to be `________` because its work is performed only when you use it to make predictions.\n",
    "\n",
    "**Answer:** lazy.\n",
    "\n",
    "**2. _(True/False)_** Each scikit-learn estimator’s `fit` method simply loads a dataset.\n",
    "\n",
    "**Answer:** False. For most, scikit-learn estimators, the `fit` method loads the data into the estimator then uses that data to perform complex calculations behind the scenes that learn from the data and train the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.2.7 Predicting Digit Classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = knn.predict(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mpredicted\u001b[49m[:\u001b[32m20\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'predicted' is not defined"
     ]
    }
   ],
   "source": [
    "predicted[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong = [(p, e) for (p, e) in zip(predicted, expected) if p != e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Self Check Exercises check mark image](files/art/check.png)\n",
    "## 16.2.7 Self Check\n",
    "**1. _(IPython Session)_** Using the `predicted` and `expected` arrays, calculate and display the prediction accuracy percentage.\n",
    "\n",
    "**Answer:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{(len(expected) - len(wrong)) / len(expected):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. _(IPython Session)_** Rewrite the list comprehension in snippet `[29]` using a for loop. Which coding style do you prefer?\n",
    "\n",
    "**Answer:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p, e in zip(predicted, expected):\n",
    "      if p != e:\n",
    "          wrong.append((p, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16.3 Case Study: Classification with k-Nearest Neighbors and the Digits Dataset, Part 2\n",
    "## 16.3.1 Metrics for Model Accuracy \n",
    "### Estimator Method `score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{knn.score(X_test, y_test):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(y_true=expected, y_pred=predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [str(digit) for digit in digits.target_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(expected, predicted, \n",
    "       target_names=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_df = pd.DataFrame(confusion, index=range(10),\n",
    "     columns=range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m axes = \u001b[43msns\u001b[49m.heatmap(confusion_df, annot=\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[32m      2\u001b[39m                     cmap=\u001b[33m'\u001b[39m\u001b[33mnipy_spectral_r\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "axes = sns.heatmap(confusion_df, annot=True, \n",
    "                    cmap='nipy_spectral_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Self Check Exercises check mark image](files/art/check.png)\n",
    "## 16.3.1 Self Check\n",
    "**1. _(Fill-In)_** A Seaborn `________` displays values as colors, often with values of higher magnitude displayed as more intense colors.\n",
    "\n",
    "**Answer:** heat map.\n",
    "\n",
    "**2. _(True/False)_** In a classification report, the precision specifies the total number of correct predictions for a class divided by the total number of samples for that class. \n",
    "\n",
    "**Answer:** True.\n",
    "\n",
    "**3. _(Discussion)_** Explain row 3 of the confusion matrix presented in this section:\n",
    "\n",
    "```\n",
    "[ 0,  0,  0, 42,  0,  1,  0,  1,  0,  0]\n",
    "```\n",
    "**Answer:** The number `42` in column index 3 indicates that 42 `3`s were correctly predicted as 3s. The number `1` at column indices 5 and 7 indicates that one `3` was incorrectly classified as a `5` and one was incorrectly classified as a `7`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.3.2 K-Fold Cross-Validation\n",
    "### KFold Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, random_state=11, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the `KFold` Object with Function `cross_val_score` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(estimator=knn, X=digits.data, \n",
    "     y=digits.target, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Mean accuracy: {scores.mean():.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Accuracy standard deviation: {scores.std():.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Self Check Exercises check mark image](files/art/check.png)\n",
    "## 16.3.2 Self Check\n",
    "**1.  _(True/False)_** Randomizing the data by shuffling it before splitting it into folds is particularly important if the samples might be ordered or grouped. \n",
    "\n",
    "**Answer:** True.\n",
    "\n",
    "**2. _(True/False)_** When you call `cross_val_score` to peform k-fold cross-validation, the function returns the best score produced while testing the model with each fold.\n",
    "\n",
    "**Answer:** False. The function returns an array containing the scores for each fold. The mean of those scores is the estimator’s overall score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.3.3 Running Multiple Models to Find the Best One "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = {\n",
    "     'KNeighborsClassifier': knn, \n",
    "     'SVC': SVC(gamma='scale'),\n",
    "     'GaussianNB': GaussianNB()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for estimator_name, estimator_object in estimators.items():\n",
    "     kfold = KFold(n_splits=10, random_state=11, shuffle=True)\n",
    "     scores = cross_val_score(estimator=estimator_object, \n",
    "         X=digits.data, y=digits.target, cv=kfold)\n",
    "     print(f'{estimator_name:>20}: ' + \n",
    "           f'mean accuracy={scores.mean():.2%}; ' +\n",
    "           f'standard deviation={scores.std():.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-Learn Estimator Diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Self Check Exercises check mark image](files/art/check.png)\n",
    "## 16.3.3 Self Check\n",
    "**1. _(True/False)_** You should choose the best estimator before performing your machine learning study.\n",
    "\n",
    "**Answer:** False. It’s difficult to know in advance which machine learning model(s) will perform best for a given dataset, especially when they hide the details of how they operate from their users. For this reason, you should run multiple models to determine which is the best for your study. \n",
    "\n",
    "**2. _(Discussion)_** How would you modify the code in this section to so that it would also test a `LinearSVC` estimator?\n",
    "\n",
    "**Answer:** You’d import the `LinearSVC` class, add a key–value pair to the `estimators` dictionary (`'LinearSVC': LinearSVC()`), then execute the `for` loop, which tests every estimator in the dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.3.4 Hyperparameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(1, 20, 2):\n",
    "     kfold = KFold(n_splits=10, random_state=11, shuffle=True)\n",
    "     knn = KNeighborsClassifier(n_neighbors=k)\n",
    "     scores = cross_val_score(estimator=knn, \n",
    "         X=digits.data, y=digits.target, cv=kfold)\n",
    "     print(f'k={k:<2}; mean accuracy={scores.mean():.2%}; ' +\n",
    "           f'standard deviation={scores.std():.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Self Check Exercises check mark image](files/art/check.png)\n",
    "## 16.3.4 Self Check\n",
    "**1. _(True/False)_** When you create an estimator object, the default hyperparameter values that scikit-learn uses are generally the best ones for every machine learning study. \n",
    "\n",
    "**Answer:** False. The default hyperparameter values make it easy for you to test estimators quickly. In real-world machine learning studies, you’ll want to use hyperparameter tuning to choose hyperparameter values that produce the best possible predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# (C) Copyright 2019 by Deitel & Associates, Inc. and                    #\n",
    "# Pearson Education, Inc. All Rights Reserved.                           #\n",
    "#                                                                        #\n",
    "# DISCLAIMER: The authors and publisher of this book have used their     #\n",
    "# best efforts in preparing the book. These efforts include the          #\n",
    "# development, research, and testing of the theories and programs        #\n",
    "# to determine their effectiveness. The authors and publisher make       #\n",
    "# no warranty of any kind, expressed or implied, with regard to these    #\n",
    "# programs or to the documentation contained in these books. The authors #\n",
    "# and publisher shall not be liable in any event for incidental or       #\n",
    "# consequential damages in connection with, or arising out of, the       #\n",
    "# furnishing, performance, or use of these programs.                     #\n",
    "##########################################################################\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
